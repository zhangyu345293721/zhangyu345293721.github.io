---
title: "揭秘盒马销量预测核心算法的技术演进"
collection: teaching
type: "时间序列预测"
permalink: /teaching/盒马销量预测技术发展
venue: "上海市"
date: 2024-04-18
location: "上海市"
---

销售预测作为供应链领域的核心算法，目前已经服务于国内数百家门店，日补货数百万SKU，为提升人力效率、减少缺货损耗发挥了重要作用。本文将揭示盒马销量预测的整体框架介绍和技术演进过程。

## 一、背景介绍

盒马围绕用户生活全场景开发了丰富的业态，提供线上线下一体化的高品质购物体验。用户可以通过移动互联网便捷下单，享受最快30分钟就能送到家的服务。为了追求极致的生鲜体验，盒马还推出了仅一天的日常生鲜系列产品，涵盖奶、菜、肉、禽等日常消费品。速食生鲜服务非常适合消费者的需求，但是对供应链提出了很高的要求。盒马供应链算法根据零售场景特点，构建了包括预测、库存、营销、价格在内的算法能力。

<br/><img src='/images/hema1.png' width="600"><br/>

销量预测作为供应链领域的核心算法，已经提供了预测商品销量的能力，包括盒马生鲜、云巢、X会员店、盒马邻里等业态。在自动补货上，也服务了很多商家的日常订单，比如盒马、盒小马、天猫校园、易客等。对提高人的效率，减少短缺和损耗有重要作用。

首先，销量预测从技术角度来看是一个重要且具有挑战的问题。的商品销量会受到很多因素的影响，除了时间上的规律性，还包括促销、调价、天气、季节性、商品状态等因素。其次，销售预测的消费场景通常很多，可以作为一种基础能力赋能更多的项目，比如商业计划书、SPT、品类规划、仓配一体化等。此外还有全自动补给。另外，销售预测使用的数据范围广，上游依赖多，技术环节长，也对算法整个环节的稳定性提出了很高的要求。


所以盒马的销售预测是围绕“预测结果准，整体链路稳，业务响应快”的思路来构建和迭代的。本文主要介绍盒马销售预测的整体框架。

## 二、整体思路


### 2.1 盒马销量预测特点

盒马销售预测的主要特点在格式上可以归纳为多业态、多品类、多场景:的三个方面，它主要支持盒马生鲜、盒马云超、盒马邻里，也包括一些外部业务；品类方面，涵盖标准品、生鲜、餐饮等多个品类，商品丰富度高；在场景方面，对影响商品销售的关键因素分别建模和优化。

<br/><img src='/images/hema2.png' width="600"><br/>


考虑到盒马格式的多样性，为了使销售预测在一定程度上贴近业务，具有通用性，对流程进行了划分：数据预处理环节和结果后处理环节会尽可能贴近业务特点，使训练数据和预测结果更好地适应业务场景；然后在算法模型的设计上更加注重结构的通用性，这样就可以通过圈定具体数据进行个体训练，快速支持不同格式和场景，同时提高开发效率。

### 2.2 销量预测技术路线

销售预测总体技术路线可以分为以下14个步骤，其中前半部分是问题的分析和定义，以及各种数据预处理，以统一建模过程中的类似工作，保证数据口径的一致性，方便后续模型的开发；中间部分是各种预测模型的构建；第二部分是模型结果的验证和融合，以及根据业务逻辑进行的后期处理。目的是提高预测结果的实用性和灵活性，实现对业务需求的快速响应。具体模块及相应介绍章节如下：

<br/><img src='/images/hema3.png' width="600"><br/>

整个流程将数据、模型、业务规则解耦，逻辑上形成一个总-子-总的结构。各部分的主要内容如下。

#### 2.2.1 问题定义与数据处理

预测问题定义：包括预测尺寸(sku/类别；销量/单量/gmv；小时/天/周)；预测口径(交易口径、业绩口径)；预测范围(需要预测哪些门店、仓库、商品)；预测渠道(APP、POS、全渠道)；预测的持续时间(7天、30天、3个月等。).结合考虑的各种因素：,的商业场景，分析了影响目标变量的因素，如营销活动、进价调整、季节性、天气、交通、相关替代、竞争、新产品、节假日、大促销等。明确数据源选择：的数据口径，确保数据来源与既定维度严格一致；确保实时数据满足业务需求。进一步处理基础数据加工：DW层的原始数据，生成适合算法的数据，如将组合商品交易拆分为单品、分析未来调价/促销活动、标注天气类型、选择日清商品圈等。根据数据业务处理：,的业务规则，数据被处理，如结算销量减少，大订单识别等。数据异常处理：,历史数据中异常值的削峰填谷，如异常值检测和时间序列填充。通用特征提取：构建了销量预测中使用的基本特征，存放在一个宽的特征表中，统一了数据口径，方便管理，提高了后续模型的开发效率。

#### 2.2.2 模型构造

算法模型构造：销售预测模型可以从不同的角度分为不同的类型。根据建模方法的不同，可以分为传统的时间序列方法、机器学习方法、深度学习方法和时空图网络方法。根据预测步骤的不同，可分为单步预测和多步预测。根据输出结果的不同，可以分为点预测和概率预测。根据目标的数量，可以分为单变量预测和多变量预测。模型构建主要集中在预测方法本身的研究，不同场景和业务问题的建模，销售预测准确度的提高。

#### 2.2.3 结果后处理


为了防止极端值对预测结果修正：,业务的负面影响，有必要截取异常值并限制模型结果的区间。根据算法模型融合：'s预测目标的特点，选择最合适的模型或模型组合，并根据一定的策略融合不同模型的预测结果。基于预测结果算法处理：算法逻辑，对预测结果进行调整，包括季节性、节假日、恶劣天气抬升等。预测结果业务处理：根据业务逻辑调整预测结果，包括BOM转换、店仓关系映射、大仓库销量汇总等。设定效果评价与分析：的算法指标(如WMAPE)和业务指标(如采用率、自动提交率)，监控整体趋势的变化；针对具体问题进行分析诊断，不断完善流程中的每一步。当向外界提供提示与使用建议：预测结果时，友好的提示可以给业务更好的指导，例如是否需要人工审核，算法考虑的因素显示在白盒中。

## 三、数据处理
### 3.1 整体框架

信息的准确性和完整性对于预测模型的效果起到了至关重要的作用,所以它需要精细的研磨和不断的迭代。为了保证数据口径的一致性，需要统一建模过程中的数据处理相关工作，包括数据源选择、基础数据处理、数据业务处理、数据异常处理、通用特征提取等。这部分最终沉淀的就是标准化的特征宽度表，方便后续模型的使用。数据处理的每个步骤的细节如下：



<br/><img src='/images/hema4.png' width="600"><br/>



需要注意的是，基础数据处理和数据业务(异常)处理的区别在于，前者生成的是客观数据，即只是在几个仓库的基础上对数据进行拆分、汇总和标记，不改变原始信息；后者生成主观数据，如缺货完成后将实际销量从0变为10，以方便模型更好地学习，提高预测结果的准确性和稳定性。

### 3.2 数据业务处理


基于每小时的销售预测，智能调控还原：智控会实时计算当天可能流失或缺货的商品，通过流量倾斜、折扣清仓等方式对库存进行调整优化。减少当天的缺货和损失。这个环节需要还原调控产生的交易(通过转化率/UV值、量价关系等。)，以保证下一个预测周期参考的历史销量更加准确。特殊交易剔除：主要根据业务逻辑和交易数据标记规则进行处理，包括对团购订单和折扣码的过滤，以及对大单(包括同一用户下的多个订单，以及同时购买组合产品和单品形成的大单)的识别和剔除。比如基础数据修正：的调价或活动审批时间晚于预期生效时间，就要以审批时间为实际生效时间；另外，当当天生效时间较晚时(比如23点生效)，需要将新价格标注为第二天生效。

<br/><img src='/images/hema5.png' width="600"><br/>


### 3.3 数据异常处理

#### 3.3.1 异常值检测

离群点检测可以分为新奇点检测和离群点检测。新颖的点检测假设训练数据不包含离群点，即通过学习历史数据，模型可以学习“正态数据”的特征和分布，然后检查新数据是否满足“正态数据”的特征。例如，在一类SVM中找到数据的边界，边界之外的数据点被视为异常值。离群点检测假设训练数据中包含离群点，即通过模型找到训练数据的中心模式，将训练数据中远离中心模式的数据点定义为离群点。比如在隔离林中，将分布稀疏且远离高密度群体的点视为离群点，然后通过不断切割数据空间来确定孤立点。

#### 3.3.2 缺失值补全

在现实场景中，由于数据采集或业务操作的原因，往往会出现数据的缺失和断点。为了保证建模过程中时间序列数据的完整性，减少后续销售预测的不良情况，需要对数据中缺失的值进行填充。有三种常见的方法来完成缺失值：

基于统计的方法,举例：线性插值，最近填充，均值/中值特征：实现简单，计算复杂度低，平均精度。例如，传统机器学习方法,KNN，GBDT特征：缺失点附近的数据用作预测缺失数据的特征。需要手工特征工程的，例如：甘特征：端到端学习，无需手工特征处理，具有一定的通用性。盒马缺失值补全的总体思路如下：方法采用深度学习方法和GBDT模型。根据当日的断货期数据、促销和价格信息，以及历史同期的销售信息，分别完成APP和POS渠道的断货期销售(下图给出了两个商品完成的例子)。此外，根据已完成的销售量和当前价格信息，可以进一步估算缺货造成的GMV损失，并将该数据提供给业务进行缺货影响分析：

<br/><img src='/images/hema6.png' width="600"><br/>


其中，GBDT属于监督学习方法。主要思路是筛选当天不缺货的样本，随机生成缺货时段，以对应时段的真实销量作为标签，然后利用历史数据构造特征进行模型训练。与统计方法相比，GBDT的完成精度可以大大提高。

GAN属于无监督学习的方法，在没有标签的数据集上也可以应用，所以通用性更强。这里采用SSGAN模型，包含三个角色：生成器的任务是输入包含缺失值的时间序列，完成后输出完整的时间序列；鉴别器的任务是判断每个时刻的数据是真实的还是算法产生的；分类器的任务是对原始时间序列和算法完成的时间序列进行分类标记，帮助生成器专注于缺失时间的完成。训练过程主要是让发生器和鉴别器对质，最后希望发生器能产生以假乱真的完整数据。考虑到GAN训练需要多个模型共同参与，且训练过程不稳定，将模型优化分解为四个步骤，对网络结构、训练策略和模块选择进行优化。从完成效果来看，SSGAN的精度高于GBDT，两种模型结合可以进一步提高精度和稳定性。具体内容如下：

<br/><img src='/images/hema7.png' width="600"><br/>

### 3.4 通用特征提取

特征工程是销售预测的关键步骤，尤其是基于传统机器学习的建模方法。这部分往往需要结合数据的内在规律和业务场景的经验进行处理。目前盒马预测使用的基本特征包括八大类：商品属性、店铺属性、促销信息、日期信息、天气信息、交通信息、历史销量、比赛信息。

在基本特征的基础上进行空间维度的交叉组合和时间维度的对齐，可以生成各种派生特征。衍生特征的进一步加权组合可以产生更丰富的特征。交叉因素越多，特征就越复杂，涵盖的信息就越多。最后，通过特征重要性评估方法选择更重要的特征来使用。

<br/><img src='/images/hema8.png' width="600"><br/>


## 四、模型构造
盒马销量预测涵盖多种方法和场景。按照方法维度可以分为四类：业务规则模型、传统机器学习模型、深度时间序列模型和时空图网络模型。每种方法都有自己的特点。通过相互结合，一方面可以保证业务需求的快速响应，提高处理各种问题的灵活性；另一方面可以兼顾前沿技术的探索和建模方法的创新。

按照场景维度可以分为一系列场景，如替代品、当季产品、日清产品、促销、流量、X会员等。细分场景进行建模，一方面可以有效提高特定场景下的预测精度，更好地支持业务应用，另一方面也有助于细化盒马销量预测的算法特点。

箱式预测算法的迭代路径如下。本节主要介绍销售预测的常用方法。

<br/><img src='/images/hema9.png' width="600"><br/>



### 4.1 传统时序方法
传统的时间序列方法主要是在确定数学模型的基础上求解模型参数，并利用求解的模型进行预测。常见的模型有MA(移动平均线)、(自回归综合移动平均线)、Prophet等。

MA是一种简单而有效的方法，因此经常作为基线与其他方法进行比较。比如SMA(简单移动平均)直接计算一段时间的历史观测值的等权平均值，但这种方法的问题是有明显的滞后性，对最近的数据不够敏感。因此，进一步的改进思路是计算历史数据的加权平均值，即数据越接近当前时间，权重越高。WMA(加权移动平均线)和EMA(指数移动平均线)都属于这种方法。主要区别是WMA的权重线性下降，而EMA的权重指数下降。ARIMA在传统时间序列方法中享有很高的声誉，其主要过程是先通过D阶差分运算将非平稳时间序列转化为平稳时间序列，然后根据平稳时间序列的自相关系数ACF和偏自相关系数PACF确定自回归项P和滑动平均项Q，并检验模型误差的随机性以确定最终模型。先知是2017年脸书的开源模型。其主要思想是对时间序列进行分解(包括趋势项、季节项、假日项和误差项)。其中，趋势项表示时间序列的非周期性趋势，季节项表示周期性变化(一般以周或年为单位)，节假日项表示时间序列中存在的特殊节假日。Prophet就是拟合这些项，然后把它们加起来作为最终的预测值。

传统时间序列方法的主要优点是建模过程简单，可解释性强。但局限性是外生变量不能有效利用，信息缺失，预测精度很难达到比较高的水平。另外，每个时间序列在使用时需要分别进行拟合和预测，数据量大的场景执行时间长。

### 4.2 传统机器学习方法
机器学习方法是销售预测常用的建模方法。常见的模型有线性回归、支持向量回归、决策树模型(GBDT、LightGBM)等。基本过程包括数据集构建特征工程模型的训练，通过监督学习从历史数据中获取特征与目标的映射关系，从而进行时间序列预测。

这种方法弥补了传统时间序列模型不能考虑外生变量的问题。在信息丰富的情况下，模型效果可以显著提升，可以应对数据量较大的场景。然而，在这类方法中，特征工程的质量往往决定了预测模型的上限，因此需要花费大量的时间来构造特征。特征工程要求算法专业的学生对业务场景有很好的理解，能够构造与目标高度相关的特征，这将对预测精度的提升带来直接的帮助。此外，为了保证预测结果的稳定性，不同场景的对齐策略、特征值计算中的降级逻辑、特殊时间点的特征转换、历史特殊日期的自动恢复或剔除也要在特征构建中考虑。除了手动构造特征，还可以使用一些特征自动生成工具生成更多的特征，如tsfresh、Featuretools等。通常情况下，自动生成的特征和人工经验的特征相结合会取得更好的效果。

值得注意的是，与传统的时间序列方法为每个时间序列建立模型进行预测不同，机器学习方法将各种数据训练在一起，得到一个全局模型。但在实际场景中，不同的时间序列所表现出来的规律可能是不一样的，比如不同品类或品牌的商品销量表现出不同的趋势和周期性。所以把所有的数据一起训练可能会导致整体预测效果的下降，所以通常需要对数据进行适当的分层，然后针对每一层数据分别训练模型。

### 4.3 深度学习方法
基于深度学习的时间序列预测方法是近年来的研究热点。由于深度学习在语音识别、计算机视觉、自然语言处理等领域取得了重要突破，相关方法也被应用于时间序列预测。主要思想是采用端到端的学习方法，输入原始数据，通过不同的模型结构自动提取特征进行学习。该方法的优化主要集中在模型结构设计和参数优化上。下面是一些经典的深度时间序列模型，包括WaveNet、DeepAR、N-Beats和TFT。

Net是Google DeepMind在2016年提出的基于CNN架构的模型。一般将CNN应用于长序列的局限性在于卷积提取局部信息，需要增加卷积核或增加模型层数来扩大感受野。WaveNet引入了扩张因果卷积，可以保证每一个瞬间都不会暴露在未来的信息中。另一方面，通过跳过一定长度的输入，可以在不增加模型层数的情况下获得更大的感受野。DeepAR是亚马逊在2017年提出的基于自回归递归神经网络的概率预测模型。它学习概率分布的参数，输出是目标值在每个时刻的概率分布。DeepAR的一大亮点是可以在几乎没有历史数据的情况下进行冷启动预测，但由于RNN结构的限制，很难补充长周期季节等信息。N-BEATS是Bengio团队在2020年发表的基于时间序列分解思想的深度网络模型。它的基本计算单位是块，多个块叠加形成一个栈。整个模型由多个栈进一步堆叠。每个块将输出前向和后向残差，后向残差将作为下一个块的输入进行拟合，前向残差之和将作为相应叠加的预测值，最后的预测结果将由所有叠加的预测值相加得到。TFT是Google提出的多变量时间序列预测模型，在输入数据的处理和网络结构的设计上比较全面。在数据处理中，TFT使用变量选择网络计算每个特征的重要性，通过加权融合减少无关变量的影响。此外，我们可以通过单独建模类别特征来更有效地利用ID信息。在网络结构上，TFT兼顾长周期和短周期定时信息(LSTM提取本地定时信息，自关注提取长周期定时信息)；通过门控单元机制，过滤掉不必要的模块信息，针对不同的数据集实现自适应的网络结构。

<br/><img src='/images/hema10.png' width="600"><br/>


综合来看，深度学习的方法更加灵活，端到端的学习方法可以减少人工处理，更加通用。此外，考虑到远距离信息在RNN模型中会被削弱或遗忘，RNN无法并行计算，因此在实际场景中会更多地使用基于注意力的方法。另外值得注意的一点是，由于机器学习方法大多采用聚合特征，对时间序列信息的把握不足，而深度时间序列模型在这方面有天然的优势，所以GAN.

### 4.4 时空图网络方法
在某些场景下，数据在时间维度和空间维度上并不独立。算法一方面需要学习时间维度的相关性，另一方面也需要考虑不同时间序列在空间维度上的相关性。例如，在商品替代场景下，当某个鸡蛋降价或缺货时，其他鸡蛋的销量会出现波动；或者在营销活动配置场景中，每种商品叠加的活动类型以及每种活动的商品池范围都会影响商品的最终价格。考虑到上述方法在这种情况下的局限性，有必要引入时空图网络对具有空间相关性的时间序列进行建模。目前，时空图网络方法已经广泛应用于交通规划、行人轨迹预测、金融分析等领域。并在盒马的预测场景中得到了一些应用，如相关替代商品的销售预测模型和营销价格预测模型。

目前常用的是STGAT模型。STGAT包括编码器和解码器两部分。在编码器中，首先利用M-LSTM对历史时间序列特征进行编码，得到每个时刻的隐含层特征。然后，用GAT捕捉每个时刻的关系图中目标sku和邻居sku的空间相关性；然后，将GAT输出的隐含层特征输入到G-LSTM进行定时传导。中间状态是将M-LSTM和G-LSTM输出的隐层特征与高斯噪声串联起来，加入高斯噪声的目的是防止网络过拟合。解码器是双层LSTM结构。下层D-LSTM传导中间状态的隐态，上层康德-LSTM加入未来商品外生变量的变化信息，将上一步的输出作为下一步的输入，实现多步预测。

<br/><img src='/images/hema11.png' width="600"><br/>


## 五、结果后处理
结果的后处理从计算方法上可以归纳为以下五种。本节将介绍主要模块：

包括识别和截取将深度时序模型和机器学习模型的结果进行融合往往能进一步提升效果模型预测结果的异常值；融合多个模型的结果。预测结果融合：;恶劣天气和特殊节假日的升力系数连续缺货拉伸；估计白盒干预等。根据预测结果调整：加工品与原料的换算关系，生成原料的预测结果；日清商品交易口径到业绩口径；切割产品时新老产品的需求继承等。基于预测结果转换：供应路由网络和门店与仓库的映射关系，汇总生成仓端销量预测结果，包括FDC、B2C仓、NB仓、CDC等。支持仓末自动补货。根据预测结果汇总：;一店多仓场景下的分仓比例拆分预测结果基于销售预测的通用拆分能力，提供门店、日、渠道的拆分能力，支持仓末销售计划和业务计划的目标拆分。

### 5.1 预测多模型融合
由于业务场景和建模方法的多样性，在两者的叠加下往往会出现预测模型的多样性。比如下面列出的盒马销量预测常规模型和特殊场景模型就有十多个。因此，这一部分需要考虑的要点是：

1)如何有效地使用这些模型，使最终的预测结果稳步提高；

2)如何让模型的管理更加方便。本文主要从模型的集成策略和模型的上线流程两个方面进行设计：

<br/><img src='/images/hema12.png' width="600"><br/>


在模型集成策略方面，第一步是根据预测目标选择合适的模型组合。需要考虑的主要因素包括商品特性、是否有特殊节假日、是否有X会员日、是否有促销活动等。那么就需要对模型的异常结果进行识别和拦截。这里使用的主要方法包括：

1)比较不同模型的预测结果，通过投票机制剔除明显异常的模型；

2)比较同一模型在当前周期和上一周期的波动来预测当天，过滤波动异常的模型；

3)基于历史统计指标的离群点过滤，如平均销售额、方差、周同期值等。

最后，融合多个模型的预测结果。这里的方法包括基于固定权重的融合策略、基于历史准确率的融合策略和基于元学习的融合方法。

就模型的在线流程而言，需要考虑的问题包括：

1)降低维护成本，即减少各型号增减后处理中的开发工作量；

2)便于评价不同模型和不同治疗策略的效果；

3)在线过程中预测模型和后处理策略的风险控制。

具体做法是：首先，你需要选择合适的数据结构来保存所有的模型结果，这样可以避免每次增减模型时对下游表字段的频繁更改。此外，还可以编写统一的udf函数，实现各种策略，提高通用性。当新模型上线时，它将首先被添加到离线总结果表中，该表包含所有模型的结果

### 5.2 预测结果算法处理
#### 5.2.1 季节性和节假日
盒马产品的销售受季节性和特殊节假日影响显著，如端午节的粽子、冬至的饺子、圣诞节的牛排和红酒等时令果蔬。季节性假期有一些共同点：

1)消费者行为存在较大不确定性，商品维度销量波动较大；

2)历史近期数据不能反映未来销售趋势，需要考虑较长时间的信息；

3)有些建模方法需要平滑历史特殊点，避免对预测产生负面影响。

此外，两个结果的不同之处在于，特殊节日的销量呈现单点脉冲式变化，而季节性商品的销量呈现连续趋势，幅度相对平缓。以下是一些常见的特殊日期：

<br/><img src='/images/hema13.png' width="600"><br/>

对于季节性和节假日场景，算法中一般有两种思路：

第一种是在预测模型层面学习历史趋势，比如在N拍中，分别用多项式函数和傅立叶级数对趋势和季节性建模；或者使用日期和类别代码关注，了解历史上类似情况的销售趋势；或者对商品维度和品类维度的销售预测进行多任务研究，驱动商品对季节趋势做出反应；另外，在传统的机器学习方法中，节假日特征的自动转换和历史数据中特殊日期的特征恢复都可以通过特征构造来实现。二是在后处理环节对销售预测结果进行调整。首先通过一定的方法计算出商品的季节/节日系数(例如统计历史上某个特殊日期相对于平日的销量增幅，或者计算品类销售预测值与聚合成品类的商品预测值的差值)，然后直接作用于预测结果。季节性和节假日的盒子销售预测的处理方法结合了以上两种思路。在后处理环节再次调整的目的是让预测结果更加灵活，能够快速响应业务需求。另外，这种方法也有很好的解释力。在这个环节中引入了品类销售预测的能力，因为品类销售预测的审核天数和预测天数都更长，更能反映年度维度的变化趋势，品类维度相对于sku维度销量波动大的问题会更稳定。具体方法是先计算品类销售预测结果和汇总到品类的商品预测结果的差异，计算品类维度的调整系数；然后对同一品类下的商品进行分层，根据分层拆分品类系数(比如头部产品的爆发力可能大于尾部产品)，以兼顾不同商品分层下销售爆发的差异；最后，将分割系数应用于预测结果。

### 5.2.2 恶劣天气
如遇下雨/降雪，或气温骤降，盒马网上销量往往会明显增加。为了避免缺货，算法需要提前感知未来的天气情况，在特殊天气情况下调整预测结果。根据下图的历史统计，夏季降雨主要集中在7-9月，降温主要集中在11-2月，这种天气一般会促进销售。目前天气应对方案结合实际业务处理经验。主要思路是统计各门店在相似天气历史中的销售增长情况，计算出品类维度的天气系数，然后应用到后处理阶段的销售预测结果中。

<br/><img src='/images/hema14.png' width="600"><br/>


#### 5.2.3 特殊事件
遇到特殊事件，往往需要人工干预。例如，新冠肺炎疫情在全国各地频繁发生。一方面，业务需要人工干预接管补货，配合供应商、物流、采购进行截留、重配、调配，导致工作量大，人力不足。另一方面，当算法遇到特殊事件时，很难跟踪和评估区域的影响，需要人工标记脏数据，因此无法沉淀标准化数据进行自动响应。特殊事件管理的目的是更好地联系所有l

盒子销售预测依靠特殊事件供应链管理产品来处理和干预异常事件。当特殊事件发生时，区域商科学生可以输入事件类型、影响时间、恐慌程度、影响范围等信息。利用以上数据，一方面算法可以自动剥离特殊事件对整个链路的影响，保证后续预测结果的稳定性；另一方面，可以根据同一历史事件中商品的销售情况(如疫情爆发时民生产品销量会大幅上升)以及需求、产能、业绩影响等业务投入的信息，计算出商品的特殊事件影响因子，从而自动响应预测。

### 5.3 预测结果业务处理
这个环节主要是根据业务规则对销售预测结果进行处理，包括根据BOM关系中的用量、产出率、成本转换率计算原材料的预测结果，推补货时扣除产成品和原材料库存。比如下面这个例子，原料“商品C”有两个成品“鲜果切商品A”和“鲜果切商品B”，原料和成品都可以销售。因此，在补充商品C时，既要考虑成品，也要考虑自身需求：


<br/><img src='/images/hema15.png' width="600"><br/>

此外，根据盒马供应路由网络和门店与仓库的映射关系，可以汇总门店销售预测结果，生成FDC和CDC的需求预测结果，进一步支持仓库的自动补货。

### 5.4 效果评估与分析
评价指标可分为预测结果拆分：和算法指标,算法指标包括MAE、RMSE、WMAPE等。用于衡量预测精度；业务指标包括采用率、缺货率、损失率、营业额等。其中，算法指标偏向于流程，用于跟踪模型在不同类别、不同时间点的变化趋势，分析诊断问题，通过不断完善算法模型最终带来商业价值；商科指标更倾向于结果，这是算法和商科学生希望共同达到的终极目标。

由于预测精度本身会受到计算口径、格式差异、商品销售水平等的影响。不建议用单一指标衡量所有格式和场景的预测效果。在算法指标的设计上，要尽可能贴近业务场景，这样才能更好的衡量算法改进对业务的影响。比如在计算准确率的时候，考虑不同商品的vlt，或者根据补货的具体场景进行统计，比如按店铺/按仓库，按天/按周。此外，我们还需要注意预测值的上下偏差。

在预测案例的分析中，首先需要及时发现问题，比如识别日缺货高、损耗高或者预测误差大的商品，以及订货业务时数量变化大、修改合理的案例；其次，需要分析影响商品销量的系统性因素，定位问题，确定14个步骤中的哪个模块需要优化解决。比如影响销量的主要因素直观展示，便于案例分析中快速定位原因，支持多模型钻取，便于对比各模型的预测。

### 5.5 提示与使用建议
该链接包含历史预测良品率、商品特性、基于算法的未来推广等信息，表示该业务是否需要人工审核。此外，通过在白盒中显示算法考虑的因素，可以实现与业务的有效协作。本章主要介绍白盒的估计。

#### 5.5.1 预估白盒化
预测白盒的主要目的是显示预测算法考虑的因素，为业务提供干扰销售预测值的能力。在断档和大促的情况下，业务可以参考未来算法预测的总额与业务预算的差异，结合算法对各种因素的响应范围，在规定的范围内调整商品预测值，在总量上达到业务预期

为了便于理解和分析，这里只选取业务的关键因素进行展示，而不是列出所有特性的重要性。目前选取四个因素：推广、流量、天气、假期。白盒系数的计算逻辑是：算法依次从原始销售预测中剥离额外流量、促销、天气、节假日等因素，得到剥离各因素后的预测结果，再计算各预测结果的相对系数，得到算法对特定因素的响应范围。比如下面这个例子，原来的销售预测结果是200，剥离额外流量的预测结果是160，那么流量因子的系数是1.25，进一步剥离促销因子后的预测结果是100，那么促销因子的系数是1.6，以此类推，可以计算出所有因素的影响：

<br/><img src='/images/hema16.png' width="600"><br/>


## 六、链路稳定性与灵活性
盒马销售预测已经服务全国数百家门店和仓库的补货，每天有数百万个SKU。为了保证日常补货的稳定性，应对门店的快速扩张和新业态的出现，销售预测整体环节沉淀了相应的降级策略和应对方案：

稳定性方面，除了保证任务本身的稳定性外，针对异常突发情况制定相应的降级策略。目前降级分为四级：数据降级主要处理上游数据输出延迟，部分数据可以前一天分区；特征退化主要是指在特征构建时可以丢弃最近一天的信息，以避免单点阻塞整个链路；模型降级主要是针对个别模型运行出现问题时，可以用其他模型的结果进行代入；在最终的结果退化部分，算法会返回每天T-1的预测结果作为当天的备份数据，如果遇到更严重的问题，会切换备份数据，从而整体提高抗风险能力。

灵活性，包括兼容业务端的变更操作，如商品的品类切换、部门切换，以及门店的子公司变更。切换前后的相关数据可以自动关联，避免对模型预测的影响；此外，还便于对外部突发因素，如公共卫生事件、自然灾害等进行干预，实现对结果的快速调整和响应。

<br/><img src='/images/hema17.png' width="600"><br/>



## 七、结束语
盒马业务目前发展迅速，丰富的场景和业态也对销售预测提出了更高的要求，需要在具体场景和整体框架上进一步打磨：一方面，销售预测需要更加贴近业务，探索和深入研究关键问题，让算法更好地服务于业务；另一方面，有必要研究一个更通用的销售预测框架，规范流程，并制定一套完善的解决方案


