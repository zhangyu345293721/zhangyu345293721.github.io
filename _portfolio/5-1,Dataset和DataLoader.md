# 5-1, Datasetå’ŒDataLoader

Pytorché€šå¸¸ä½¿ç”¨Datasetå’ŒDataLoaderè¿™ä¸¤ä¸ªå·¥å…·ç±»æ¥æ„å»ºæ•°æ®ç®¡é“ã€‚

Datasetå®šä¹‰äº†æ•°æ®é›†çš„å†…å®¹ï¼Œå®ƒç›¸å½“äºä¸€ä¸ªç±»ä¼¼åˆ—è¡¨çš„æ•°æ®ç»“æ„ï¼Œå…·æœ‰ç¡®å®šçš„é•¿åº¦ï¼Œèƒ½å¤Ÿç”¨ç´¢å¼•è·å–æ•°æ®é›†ä¸­çš„å…ƒç´ ã€‚

è€ŒDataLoaderå®šä¹‰äº†æŒ‰batchåŠ è½½æ•°æ®é›†çš„æ–¹æ³•ï¼Œå®ƒæ˜¯ä¸€ä¸ªå®ç°äº†`__iter__`æ–¹æ³•çš„å¯è¿­ä»£å¯¹è±¡ï¼Œæ¯æ¬¡è¿­ä»£è¾“å‡ºä¸€ä¸ªbatchçš„æ•°æ®ã€‚

DataLoaderèƒ½å¤Ÿæ§åˆ¶batchçš„å¤§å°ï¼Œbatchä¸­å…ƒç´ çš„é‡‡æ ·æ–¹æ³•ï¼Œä»¥åŠå°†batchç»“æœæ•´ç†æˆæ¨¡å‹æ‰€éœ€è¾“å…¥å½¢å¼çš„æ–¹æ³•ï¼Œå¹¶ä¸”èƒ½å¤Ÿä½¿ç”¨å¤šè¿›ç¨‹è¯»å–æ•°æ®ã€‚

åœ¨ç»å¤§éƒ¨åˆ†æƒ…å†µä¸‹ï¼Œç”¨æˆ·åªéœ€å®ç°Datasetçš„`__len__`æ–¹æ³•å’Œ`__getitem__`æ–¹æ³•ï¼Œå°±å¯ä»¥è½»æ¾æ„å»ºè‡ªå·±çš„æ•°æ®é›†ï¼Œå¹¶ç”¨é»˜è®¤æ•°æ®ç®¡é“è¿›è¡ŒåŠ è½½ã€‚





```python
import torch 
import torchvision

print("torch.__version__="+torch.__version__) 
print("torchvision.__version__="+torchvision.__version__) 

```

    torch.__version__=2.0.1
    torchvision.__version__=0.15.2


<br>

<font color="red">
 
å…¬ä¼—å· **ç®—æ³•ç¾é£Ÿå±‹** å›å¤å…³é”®è¯ï¼š**pytorch**ï¼Œ è·å–æœ¬é¡¹ç›®æºç å’Œæ‰€ç”¨æ•°æ®é›†ç™¾åº¦äº‘ç›˜ä¸‹è½½é“¾æ¥ã€‚
    
</font> 


### ä¸€ï¼Œæ·±å…¥ç†è§£Datasetå’ŒDataLoaderåŸç†

**1ï¼Œè·å–ä¸€ä¸ªbatchæ•°æ®çš„æ­¥éª¤**

è®©æˆ‘ä»¬è€ƒè™‘ä¸€ä¸‹ä»ä¸€ä¸ªæ•°æ®é›†ä¸­è·å–ä¸€ä¸ªbatchçš„æ•°æ®éœ€è¦å“ªäº›æ­¥éª¤ã€‚

(å‡å®šæ•°æ®é›†çš„ç‰¹å¾å’Œæ ‡ç­¾åˆ†åˆ«è¡¨ç¤ºä¸ºå¼ é‡`X`å’Œ`Y`ï¼Œæ•°æ®é›†å¯ä»¥è¡¨ç¤ºä¸º`(X,Y)`, å‡å®šbatchå¤§å°ä¸º`m`)

1ï¼Œé¦–å…ˆæˆ‘ä»¬è¦ç¡®å®šæ•°æ®é›†çš„é•¿åº¦`n`ã€‚

ç»“æœç±»ä¼¼ï¼š`n = 1000`ã€‚

2ï¼Œç„¶åæˆ‘ä»¬ä»`0`åˆ°`n-1`çš„èŒƒå›´ä¸­æŠ½æ ·å‡º`m`ä¸ªæ•°(batchå¤§å°)ã€‚

å‡å®š`m=4`, æ‹¿åˆ°çš„ç»“æœæ˜¯ä¸€ä¸ªåˆ—è¡¨ï¼Œç±»ä¼¼ï¼š`indices = [1,4,8,9]`

3ï¼Œæ¥ç€æˆ‘ä»¬ä»æ•°æ®é›†ä¸­å»å–è¿™`m`ä¸ªæ•°å¯¹åº”ä¸‹æ ‡çš„å…ƒç´ ã€‚

æ‹¿åˆ°çš„ç»“æœæ˜¯ä¸€ä¸ªå…ƒç»„åˆ—è¡¨ï¼Œç±»ä¼¼ï¼š`samples = [(X[1],Y[1]),(X[4],Y[4]),(X[8],Y[8]),(X[9],Y[9])]`

4ï¼Œæœ€åæˆ‘ä»¬å°†ç»“æœæ•´ç†æˆä¸¤ä¸ªå¼ é‡ä½œä¸ºè¾“å‡ºã€‚

æ‹¿åˆ°çš„ç»“æœæ˜¯ä¸¤ä¸ªå¼ é‡ï¼Œç±»ä¼¼`batch = (features,labels) `ï¼Œ 

å…¶ä¸­ `features = torch.stack([X[1],X[4],X[8],X[9]])`

`labels = torch.stack([Y[1],Y[4],Y[8],Y[9]])`



```python

```

**2ï¼ŒDatasetå’ŒDataLoaderçš„åŠŸèƒ½åˆ†å·¥**

ä¸Šè¿°ç¬¬1ä¸ªæ­¥éª¤ç¡®å®šæ•°æ®é›†çš„é•¿åº¦æ˜¯ç”± Datasetçš„`__len__` æ–¹æ³•å®ç°çš„ã€‚

ç¬¬2ä¸ªæ­¥éª¤ä»`0`åˆ°`n-1`çš„èŒƒå›´ä¸­æŠ½æ ·å‡º`m`ä¸ªæ•°çš„æ–¹æ³•æ˜¯ç”± DataLoaderçš„ `sampler`å’Œ `batch_sampler`å‚æ•°æŒ‡å®šçš„ã€‚

`sampler`å‚æ•°æŒ‡å®šå•ä¸ªå…ƒç´ æŠ½æ ·æ–¹æ³•ï¼Œä¸€èˆ¬æ— éœ€ç”¨æˆ·è®¾ç½®ï¼Œç¨‹åºé»˜è®¤åœ¨DataLoaderçš„å‚æ•°`shuffle=True`æ—¶é‡‡ç”¨éšæœºæŠ½æ ·ï¼Œ`shuffle=False`æ—¶é‡‡ç”¨é¡ºåºæŠ½æ ·ã€‚

`batch_sampler`å‚æ•°å°†å¤šä¸ªæŠ½æ ·çš„å…ƒç´ æ•´ç†æˆä¸€ä¸ªåˆ—è¡¨ï¼Œä¸€èˆ¬æ— éœ€ç”¨æˆ·è®¾ç½®ï¼Œé»˜è®¤æ–¹æ³•åœ¨DataLoaderçš„å‚æ•°`drop_last=True`æ—¶ä¼šä¸¢å¼ƒæ•°æ®é›†æœ€åä¸€ä¸ªé•¿åº¦ä¸èƒ½è¢«batchå¤§å°æ•´é™¤çš„æ‰¹æ¬¡ï¼Œåœ¨`drop_last=False`æ—¶ä¿ç•™æœ€åä¸€ä¸ªæ‰¹æ¬¡ã€‚

ç¬¬3ä¸ªæ­¥éª¤çš„æ ¸å¿ƒé€»è¾‘æ ¹æ®ä¸‹æ ‡å–æ•°æ®é›†ä¸­çš„å…ƒç´  æ˜¯ç”± Datasetçš„ `__getitem__`æ–¹æ³•å®ç°çš„ã€‚

ç¬¬4ä¸ªæ­¥éª¤çš„é€»è¾‘ç”±DataLoaderçš„å‚æ•°`collate_fn`æŒ‡å®šã€‚ä¸€èˆ¬æƒ…å†µä¸‹ä¹Ÿæ— éœ€ç”¨æˆ·è®¾ç½®ã€‚


Datasetå’ŒDataLoaderçš„ä¸€èˆ¬ä½¿ç”¨æ–¹å¼å¦‚ä¸‹ï¼š


```python
import torch 
from torch.utils.data import TensorDataset,Dataset,DataLoader
from torch.utils.data import RandomSampler,BatchSampler 


ds = TensorDataset(torch.randn(1000,3),
                   torch.randint(low=0,high=2,size=(1000,)).float())
dl = DataLoader(ds,batch_size=4,drop_last = False)
features,labels = next(iter(dl))
print("features = ",features )
print("labels = ",labels )  


```

    features =  tensor([[ 0.4871, -0.4812, -0.0125],
            [-1.0566, -1.1058,  0.1595],
            [ 0.8301,  1.2801, -1.9947],
            [-0.1087,  0.1810, -1.0611]])
    labels =  tensor([0., 1., 1., 0.])


```
features =  tensor([[-0.3979,  0.4728, -0.9796],
        [-1.0995,  0.7045,  0.7593],
        [-0.9703, -0.6259, -0.2886],
        [-1.1529, -0.7042, -0.8151]])
labels =  tensor([1., 0., 0., 0.])
```

å°†DataLoaderå†…éƒ¨è°ƒç”¨æ–¹å¼æ­¥éª¤æ‹†è§£å¦‚ä¸‹ï¼š


```python
# step1: ç¡®å®šæ•°æ®é›†é•¿åº¦ (Datasetçš„ __len__ æ–¹æ³•å®ç°)
ds = TensorDataset(torch.randn(1000,3),
                   torch.randint(low=0,high=2,size=(1000,)).float())
print("n = ", len(ds)) # len(ds)ç­‰ä»·äº ds.__len__()

# step2: ç¡®å®šæŠ½æ ·indices (DataLoaderä¸­çš„ Samplerå’ŒBatchSamplerå®ç°)
sampler = RandomSampler(data_source = ds)
batch_sampler = BatchSampler(sampler = sampler, 
                             batch_size = 4, drop_last = False)
for idxs in batch_sampler:
    indices = idxs
    break 
print("indices = ",indices)

# step3: å–å‡ºä¸€æ‰¹æ ·æœ¬batch (Datasetçš„ __getitem__ æ–¹æ³•å®ç°)
batch = [ds[i] for i in  indices]  #  ds[i] ç­‰ä»·äº ds.__getitem__(i)
print("batch = ", batch)

# step4: æ•´ç†æˆfeatureså’Œlabels (DataLoader çš„ collate_fn æ–¹æ³•å®ç°)
def collate_fn(batch):
    features = torch.stack([sample[0] for sample in batch])
    labels = torch.stack([sample[1] for sample in batch])
    return features,labels 

features,labels = collate_fn(batch)
print("features = ",features)
print("labels = ",labels)

```

    n =  1000
    indices =  [63, 672, 994, 283]
    batch =  [(tensor([-0.0396, -0.2129,  0.9823]), tensor(1.)), (tensor([-1.5184,  0.9135,  0.2675]), tensor(1.)), (tensor([-1.4275,  1.7845, -1.4629]), tensor(0.)), (tensor([-1.2925,  1.2267,  1.0238]), tensor(1.))]
    features =  tensor([[-0.0396, -0.2129,  0.9823],
            [-1.5184,  0.9135,  0.2675],
            [-1.4275,  1.7845, -1.4629],
            [-1.2925,  1.2267,  1.0238]])
    labels =  tensor([1., 1., 0., 1.])



```python

```

**3ï¼ŒDatasetå’ŒDataLoaderçš„æ ¸å¿ƒæºç **

ä»¥ä¸‹æ˜¯ Datasetå’Œ DataLoaderçš„æ ¸å¿ƒæºç ï¼Œçœç•¥äº†ä¸ºäº†æå‡æ€§èƒ½è€Œå¼•å…¥çš„è¯¸å¦‚å¤šè¿›ç¨‹è¯»å–æ•°æ®ç›¸å…³çš„ä»£ç ã€‚



```python
import torch 
class Dataset(object):
    def __init__(self):
        pass
    
    def __len__(self):
        raise NotImplementedError
        
    def __getitem__(self,index):
        raise NotImplementedError
        

class DataLoader(object):
    def __init__(self,dataset,batch_size,collate_fn = None,shuffle = True,drop_last = False):
        self.dataset = dataset
        self.collate_fn = collate_fn
        self.sampler =torch.utils.data.RandomSampler if shuffle else \
           torch.utils.data.SequentialSampler
        self.batch_sampler = torch.utils.data.BatchSampler
        self.sample_iter = self.batch_sampler(
            self.sampler(self.dataset),
            batch_size = batch_size,drop_last = drop_last)
        self.collate_fn = collate_fn if collate_fn is not None else \
            torch.utils.data._utils.collate.default_collate
        
    def __next__(self):
        indices = next(iter(self.sample_iter))
        batch = self.collate_fn([self.dataset[i] for i in indices])
        return batch
    
    def __iter__(self):
        return self
    
```

æˆ‘ä»¬æ¥æµ‹è¯•ä¸€ç•ª


```python
class ToyDataset(Dataset):
    def __init__(self,X,Y):
        self.X = X
        self.Y = Y 
    def __len__(self):
        return len(self.X)
    def __getitem__(self,index):
        return self.X[index],self.Y[index]
    
X,Y = torch.randn(1000,3),torch.randint(low=0,high=2,size=(1000,)).float()
ds = ToyDataset(X,Y)

dl = DataLoader(ds,batch_size=4,drop_last = False)
features,labels = next(iter(dl))
print("features = ",features )
print("labels = ",labels )  
```

    features =  tensor([[-0.8581, -1.1772,  0.1349],
            [ 0.7672, -0.1178, -0.1553],
            [ 1.4551,  1.9753,  1.4102],
            [-0.1069, -0.6730, -0.2066]])
    labels =  tensor([0., 0., 0., 1.])


```
features =  tensor([[ 0.6718, -0.5819,  0.9362],
        [-0.4208, -0.1517,  0.3838],
        [ 2.1848, -1.2617,  0.7580],
        [ 0.1418, -1.6424,  0.3673]])
labels =  tensor([0., 1., 1., 0.])
```

å®Œç¾, å’Œé¢„æœŸä¸€è‡´!


```python

```

### äºŒï¼Œä½¿ç”¨Datasetåˆ›å»ºæ•°æ®é›†

Datasetåˆ›å»ºæ•°æ®é›†å¸¸ç”¨çš„æ–¹æ³•æœ‰ï¼š

* ä½¿ç”¨ torch.utils.data.TensorDataset æ ¹æ®Tensoråˆ›å»ºæ•°æ®é›†(numpyçš„arrayï¼ŒPandasçš„DataFrameéœ€è¦å…ˆè½¬æ¢æˆTensor)ã€‚

* ä½¿ç”¨ torchvision.datasets.ImageFolder æ ¹æ®å›¾ç‰‡ç›®å½•åˆ›å»ºå›¾ç‰‡æ•°æ®é›†ã€‚

* ç»§æ‰¿ torch.utils.data.Dataset åˆ›å»ºè‡ªå®šä¹‰æ•°æ®é›†ã€‚


æ­¤å¤–ï¼Œè¿˜å¯ä»¥é€šè¿‡

* torch.utils.data.random_split å°†ä¸€ä¸ªæ•°æ®é›†åˆ†å‰²æˆå¤šä»½ï¼Œå¸¸ç”¨äºåˆ†å‰²è®­ç»ƒé›†ï¼ŒéªŒè¯é›†å’Œæµ‹è¯•é›†ã€‚

* è°ƒç”¨Datasetçš„åŠ æ³•è¿ç®—ç¬¦(`+`)å°†å¤šä¸ªæ•°æ®é›†åˆå¹¶æˆä¸€ä¸ªæ•°æ®é›†ã€‚


**1ï¼Œæ ¹æ®Tensoråˆ›å»ºæ•°æ®é›†**


```python
import numpy as np 
import torch 
from torch.utils.data import TensorDataset,Dataset,DataLoader,random_split 

```


```python
# æ ¹æ®Tensoråˆ›å»ºæ•°æ®é›†

from sklearn import datasets 
iris = datasets.load_iris()
ds_iris = TensorDataset(torch.tensor(iris.data),torch.tensor(iris.target))

# åˆ†å‰²æˆè®­ç»ƒé›†å’Œé¢„æµ‹é›†
n_train = int(len(ds_iris)*0.8)
n_val = len(ds_iris) - n_train
ds_train,ds_val = random_split(ds_iris,[n_train,n_val])

print(type(ds_iris))
print(type(ds_train))

```

    <class 'torch.utils.data.dataset.TensorDataset'>
    <class 'torch.utils.data.dataset.Subset'>



```python
# ä½¿ç”¨DataLoaderåŠ è½½æ•°æ®é›†
dl_train,dl_val = DataLoader(ds_train,batch_size = 8),DataLoader(ds_val,batch_size = 8)

for features,labels in dl_train:
    print(features,labels)
    break
```

    tensor([[5.6000, 3.0000, 4.1000, 1.3000],
            [5.1000, 3.8000, 1.6000, 0.2000],
            [4.8000, 3.0000, 1.4000, 0.3000],
            [4.8000, 3.0000, 1.4000, 0.1000],
            [6.4000, 3.2000, 5.3000, 2.3000],
            [4.4000, 3.2000, 1.3000, 0.2000],
            [5.6000, 2.9000, 3.6000, 1.3000],
            [6.3000, 2.9000, 5.6000, 1.8000]], dtype=torch.float64) tensor([1, 0, 0, 0, 2, 0, 1, 2])



```python
# æ¼”ç¤ºåŠ æ³•è¿ç®—ç¬¦ï¼ˆ`+`ï¼‰çš„åˆå¹¶ä½œç”¨

ds_data = ds_train + ds_val

print('len(ds_train) = ',len(ds_train))
print('len(ds_valid) = ',len(ds_val))
print('len(ds_train+ds_valid) = ',len(ds_data))

print(type(ds_data))

```

    len(ds_train) =  120
    len(ds_valid) =  30
    len(ds_train+ds_valid) =  150
    <class 'torch.utils.data.dataset.ConcatDataset'>



```python

```

**2ï¼Œæ ¹æ®å›¾ç‰‡ç›®å½•åˆ›å»ºå›¾ç‰‡æ•°æ®é›†**


```python
import numpy as np 
import torch 
from torch.utils.data import DataLoader
from torchvision import transforms,datasets 

```


```python
#æ¼”ç¤ºä¸€äº›å¸¸ç”¨çš„å›¾ç‰‡å¢å¼ºæ“ä½œ
```


```python
from PIL import Image
img = Image.open('./data/cat.jpeg')
img
```




    
![png](output_34_0.png)
    




```python
# éšæœºæ•°å€¼ç¿»è½¬
transforms.RandomVerticalFlip()(img)
```




    
![png](output_35_0.png)
    




```python
#éšæœºæ—‹è½¬
transforms.RandomRotation(45)(img)
```




    
![png](output_36_0.png)
    




```python
# å®šä¹‰å›¾ç‰‡å¢å¼ºæ“ä½œ

transform_train = transforms.Compose([
   transforms.RandomHorizontalFlip(), #éšæœºæ°´å¹³ç¿»è½¬
   transforms.RandomVerticalFlip(), #éšæœºå‚ç›´ç¿»è½¬
   transforms.RandomRotation(45),  #éšæœºåœ¨45åº¦è§’åº¦å†…æ—‹è½¬
   transforms.ToTensor() #è½¬æ¢æˆå¼ é‡
  ]
) 

transform_valid = transforms.Compose([
    transforms.ToTensor()
  ]
)

```


```python
# æ ¹æ®å›¾ç‰‡ç›®å½•åˆ›å»ºæ•°æ®é›†

def transform_label(x):
    return torch.tensor([x]).float()

ds_train = datasets.ImageFolder("./eat_pytorch_datasets/cifar2/train/",
            transform = transform_train,target_transform= transform_label)
ds_val = datasets.ImageFolder("./eat_pytorch_datasets/cifar2/test/",
                              transform = transform_valid,
                              target_transform= transform_label)


print(ds_train.class_to_idx)

# ä½¿ç”¨DataLoaderåŠ è½½æ•°æ®é›†

dl_train = DataLoader(ds_train,batch_size = 50,shuffle = True)
dl_val = DataLoader(ds_val,batch_size = 50,shuffle = True)


for features,labels in dl_train:
    print(features.shape)
    print(labels.shape)
    break
    
```

    {'0_airplane': 0, '1_automobile': 1}
    torch.Size([50, 3, 32, 32])
    torch.Size([50, 1])



```python

```


```python

```

**3ï¼Œåˆ›å»ºè‡ªå®šä¹‰æ•°æ®é›†**

ä¸‹é¢æˆ‘ä»¬é€šè¿‡å¦å¤–ä¸€ç§æ–¹å¼ï¼Œå³ç»§æ‰¿ torch.utils.data.Dataset åˆ›å»ºè‡ªå®šä¹‰æ•°æ®é›†çš„æ–¹å¼æ¥å¯¹ cifar2æ„å»º æ•°æ®ç®¡é“ã€‚



```python
from pathlib import Path 
from PIL import Image 

class Cifar2Dataset(Dataset):
    def __init__(self,imgs_dir,img_transform):
        self.files = list(Path(imgs_dir).rglob("*.jpg"))
        self.transform = img_transform
        
    def __len__(self,):
        return len(self.files)
    
    def __getitem__(self,i):
        file_i = str(self.files[i])
        img = Image.open(file_i)
        tensor = self.transform(img)
        label = torch.tensor([1.0]) if  "1_automobile" in file_i else torch.tensor([0.0])
        return tensor,label 
    
    
train_dir = "./eat_pytorch_datasets/cifar2/train/"
test_dir = "./eat_pytorch_datasets/cifar2/test/"

            
```


```python
# å®šä¹‰å›¾ç‰‡å¢å¼º
transform_train = transforms.Compose([
   transforms.RandomHorizontalFlip(), #éšæœºæ°´å¹³ç¿»è½¬
   transforms.RandomVerticalFlip(), #éšæœºå‚ç›´ç¿»è½¬
   transforms.RandomRotation(45),  #éšæœºåœ¨45åº¦è§’åº¦å†…æ—‹è½¬
   transforms.ToTensor() #è½¬æ¢æˆå¼ é‡
  ]
) 

transform_val = transforms.Compose([
    transforms.ToTensor()
  ]
)
```


```python
ds_train = Cifar2Dataset(train_dir,transform_train)
ds_val = Cifar2Dataset(test_dir,transform_val)


dl_train = DataLoader(ds_train,batch_size = 50,shuffle = True)
dl_val = DataLoader(ds_val,batch_size = 50,shuffle = True)


for features,labels in dl_train:
    print(features.shape)
    print(labels.shape)
    break
    

```

    torch.Size([50, 3, 32, 32])
    torch.Size([50, 1])



```python

```

### ä¸‰ï¼Œä½¿ç”¨DataLoaderåŠ è½½æ•°æ®é›†

DataLoaderèƒ½å¤Ÿæ§åˆ¶batchçš„å¤§å°ï¼Œbatchä¸­å…ƒç´ çš„é‡‡æ ·æ–¹æ³•ï¼Œä»¥åŠå°†batchç»“æœæ•´ç†æˆæ¨¡å‹æ‰€éœ€è¾“å…¥å½¢å¼çš„æ–¹æ³•ï¼Œå¹¶ä¸”èƒ½å¤Ÿä½¿ç”¨å¤šè¿›ç¨‹è¯»å–æ•°æ®ã€‚

DataLoaderçš„å‡½æ•°ç­¾åå¦‚ä¸‹ã€‚

```python
DataLoader(
    dataset,
    batch_size=1,
    shuffle=False,
    sampler=None,
    batch_sampler=None,
    num_workers=0,
    collate_fn=None,
    pin_memory=False,
    drop_last=False,
    timeout=0,
    worker_init_fn=None,
    multiprocessing_context=None,
)
```


ä¸€èˆ¬æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬ä»…ä»…ä¼šé…ç½® dataset, batch_size, shuffle, num_workers,pin_memory, drop_lastè¿™å…­ä¸ªå‚æ•°ï¼Œ

æœ‰æ—¶å€™å¯¹äºä¸€äº›å¤æ‚ç»“æ„çš„æ•°æ®é›†ï¼Œè¿˜éœ€è¦è‡ªå®šä¹‰collate_fnå‡½æ•°ï¼Œå…¶ä»–å‚æ•°ä¸€èˆ¬ä½¿ç”¨é»˜è®¤å€¼å³å¯ã€‚

DataLoaderé™¤äº†å¯ä»¥åŠ è½½æˆ‘ä»¬å‰é¢è®²çš„ torch.utils.data.Dataset å¤–ï¼Œè¿˜èƒ½å¤ŸåŠ è½½å¦å¤–ä¸€ç§æ•°æ®é›† torch.utils.data.IterableDatasetã€‚

å’ŒDatasetæ•°æ®é›†ç›¸å½“äºä¸€ç§åˆ—è¡¨ç»“æ„ä¸åŒï¼ŒIterableDatasetç›¸å½“äºä¸€ç§è¿­ä»£å™¨ç»“æ„ã€‚ å®ƒæ›´åŠ å¤æ‚ï¼Œä¸€èˆ¬è¾ƒå°‘ä½¿ç”¨ã€‚

- dataset : æ•°æ®é›†
- batch_size: æ‰¹æ¬¡å¤§å°
- shuffle: æ˜¯å¦ä¹±åº
- sampler: æ ·æœ¬é‡‡æ ·å‡½æ•°ï¼Œä¸€èˆ¬æ— éœ€è®¾ç½®ã€‚
- batch_sampler: æ‰¹æ¬¡é‡‡æ ·å‡½æ•°ï¼Œä¸€èˆ¬æ— éœ€è®¾ç½®ã€‚
- num_workers: ä½¿ç”¨å¤šè¿›ç¨‹è¯»å–æ•°æ®ï¼Œè®¾ç½®çš„è¿›ç¨‹æ•°ã€‚
- collate_fn: æ•´ç†ä¸€ä¸ªæ‰¹æ¬¡æ•°æ®çš„å‡½æ•°ã€‚
- pin_memory: æ˜¯å¦è®¾ç½®ä¸ºé”ä¸šå†…å­˜ã€‚é»˜è®¤ä¸ºFalseï¼Œé”ä¸šå†…å­˜ä¸ä¼šä½¿ç”¨è™šæ‹Ÿå†…å­˜(ç¡¬ç›˜)ï¼Œä»é”ä¸šå†…å­˜æ‹·è´åˆ°GPUä¸Šé€Ÿåº¦ä¼šæ›´å¿«ã€‚
- drop_last: æ˜¯å¦ä¸¢å¼ƒæœ€åä¸€ä¸ªæ ·æœ¬æ•°é‡ä¸è¶³batch_sizeæ‰¹æ¬¡æ•°æ®ã€‚
- timeout: åŠ è½½ä¸€ä¸ªæ•°æ®æ‰¹æ¬¡çš„æœ€é•¿ç­‰å¾…æ—¶é—´ï¼Œä¸€èˆ¬æ— éœ€è®¾ç½®ã€‚
- worker_init_fn: æ¯ä¸ªworkerä¸­datasetçš„åˆå§‹åŒ–å‡½æ•°ï¼Œå¸¸ç”¨äº IterableDatasetã€‚ä¸€èˆ¬ä¸ä½¿ç”¨ã€‚




```python
#æ„å»ºè¾“å…¥æ•°æ®ç®¡é“
ds = TensorDataset(torch.arange(1,50))
dl = DataLoader(ds,
                batch_size = 10,
                shuffle= True,
                num_workers=2,
                drop_last = True)
#è¿­ä»£æ•°æ®
for batch, in dl:
    print(batch)
```

    tensor([45, 49, 27,  7, 32, 48, 19, 38, 35, 30])
    tensor([44, 37, 21, 39, 29, 13,  8, 31, 33,  5])
    tensor([34, 28,  2, 23, 15, 42, 43, 40, 22,  6])
    tensor([36,  3, 46,  9, 26, 16, 12, 17, 18,  1])



```python

```

**å¦‚æœæœ¬ä¹¦å¯¹ä½ æœ‰æ‰€å¸®åŠ©ï¼Œæƒ³é¼“åŠ±ä¸€ä¸‹ä½œè€…ï¼Œè®°å¾—ç»™æœ¬é¡¹ç›®åŠ ä¸€é¢—æ˜Ÿæ˜Ÿstarâ­ï¸ï¼Œå¹¶åˆ†äº«ç»™ä½ çš„æœ‹å‹ä»¬å–”ğŸ˜Š!** 

å¦‚æœå¯¹æœ¬ä¹¦å†…å®¹ç†è§£ä¸Šæœ‰éœ€è¦è¿›ä¸€æ­¥å’Œä½œè€…äº¤æµçš„åœ°æ–¹ï¼Œæ¬¢è¿åœ¨å…¬ä¼—å·"ç®—æ³•ç¾é£Ÿå±‹"ä¸‹ç•™è¨€ã€‚ä½œè€…æ—¶é—´å’Œç²¾åŠ›æœ‰é™ï¼Œä¼šé…Œæƒ…äºˆä»¥å›å¤ã€‚

ä¹Ÿå¯ä»¥åœ¨å…¬ä¼—å·åå°å›å¤å…³é”®å­—ï¼š**åŠ ç¾¤**ï¼ŒåŠ å…¥è¯»è€…äº¤æµç¾¤å’Œå¤§å®¶è®¨è®ºã€‚

![ç®—æ³•ç¾é£Ÿå±‹logo.png](https://tva1.sinaimg.cn/large/e6c9d24egy1h41m2zugguj20k00b9q46.jpg)


```python

```
