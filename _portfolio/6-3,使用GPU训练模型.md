# 6-3,ä½¿ç”¨GPUè®­ç»ƒæ¨¡å‹

æ·±åº¦å­¦ä¹ çš„è®­ç»ƒè¿‡ç¨‹å¸¸å¸¸éå¸¸è€—æ—¶ï¼Œä¸€ä¸ªæ¨¡å‹è®­ç»ƒå‡ ä¸ªå°æ—¶æ˜¯å®¶å¸¸ä¾¿é¥­ï¼Œè®­ç»ƒå‡ å¤©ä¹Ÿæ˜¯å¸¸æœ‰çš„äº‹æƒ…ï¼Œæœ‰æ—¶å€™ç”šè‡³è¦è®­ç»ƒå‡ åå¤©ã€‚

è®­ç»ƒè¿‡ç¨‹çš„è€—æ—¶ä¸»è¦æ¥è‡ªäºä¸¤ä¸ªéƒ¨åˆ†ï¼Œä¸€éƒ¨åˆ†æ¥è‡ªæ•°æ®å‡†å¤‡ï¼Œå¦ä¸€éƒ¨åˆ†æ¥è‡ªå‚æ•°è¿­ä»£ã€‚

å½“æ•°æ®å‡†å¤‡è¿‡ç¨‹è¿˜æ˜¯æ¨¡å‹è®­ç»ƒæ—¶é—´çš„ä¸»è¦ç“¶é¢ˆæ—¶ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨æ›´å¤šè¿›ç¨‹æ¥å‡†å¤‡æ•°æ®ã€‚

å½“å‚æ•°è¿­ä»£è¿‡ç¨‹æˆä¸ºè®­ç»ƒæ—¶é—´çš„ä¸»è¦ç“¶é¢ˆæ—¶ï¼Œæˆ‘ä»¬é€šå¸¸çš„æ–¹æ³•æ˜¯åº”ç”¨GPUæ¥è¿›è¡ŒåŠ é€Ÿã€‚


```python
!pip install -q torchkeras 
!pip install -q  -U torchmetrics
```


```python
import torch 
import torchkeras 
import torchmetrics

print("torch.__version__ = ",torch.__version__)
print("torchkeras.__version__ = ",torchkeras.__version__)
print("torchmetrics.__version__ = ",torchmetrics.__version__)
```

    torch.__version__ =  1.11.0
    torchkeras.__version__ =  3.9.3
    torchmetrics.__version__ =  0.11.4


æ³¨ï¼šæœ¬èŠ‚ä»£ç åªèƒ½åœ¨æœ‰GPUçš„æœºå™¨ç¯å¢ƒä¸Šæ‰èƒ½æ­£ç¡®æ‰§è¡Œã€‚

å¯¹äºæ²¡æœ‰GPUçš„åŒå­¦ï¼Œæ¨èä½¿ç”¨

åœ¨Colabç¬”è®°æœ¬ä¸­ï¼šä¿®æ”¹->ç¬”è®°æœ¬è®¾ç½®->ç¡¬ä»¶åŠ é€Ÿå™¨ ä¸­é€‰æ‹© GPU

å¯ç‚¹å‡»å¦‚ä¸‹é“¾æ¥ï¼Œç›´æ¥åœ¨kaggleä¸­è¿è¡ŒèŒƒä¾‹ä»£ç ã€‚

https://www.kaggle.com/lyhue1991/pytorch-gpu-examples

Pytorchä¸­ä½¿ç”¨GPUåŠ é€Ÿæ¨¡å‹éå¸¸ç®€å•ï¼Œåªè¦å°†æ¨¡å‹å’Œæ•°æ®ç§»åŠ¨åˆ°GPUä¸Šã€‚æ ¸å¿ƒä»£ç åªæœ‰ä»¥ä¸‹å‡ è¡Œã€‚

```python
# å®šä¹‰æ¨¡å‹
... 

device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
model.to(device) # ç§»åŠ¨æ¨¡å‹åˆ°cuda

# è®­ç»ƒæ¨¡å‹
...

features = features.to(device) # ç§»åŠ¨æ•°æ®åˆ°cuda
labels = labels.to(device) # æˆ–è€…  labels = labels.cuda() if torch.cuda.is_available() else labels
...
```

å¦‚æœè¦ä½¿ç”¨å¤šä¸ªGPUè®­ç»ƒæ¨¡å‹ï¼Œä¹Ÿéå¸¸ç®€å•ã€‚åªéœ€è¦åœ¨å°†æ¨¡å‹è®¾ç½®ä¸ºæ•°æ®å¹¶è¡Œé£æ ¼æ¨¡å‹ã€‚
åˆ™æ¨¡å‹ç§»åŠ¨åˆ°GPUä¸Šä¹‹åï¼Œä¼šåœ¨æ¯ä¸€ä¸ªGPUä¸Šæ‹·è´ä¸€ä¸ªå‰¯æœ¬ï¼Œå¹¶æŠŠæ•°æ®å¹³åˆ†åˆ°å„ä¸ªGPUä¸Šè¿›è¡Œè®­ç»ƒã€‚æ ¸å¿ƒä»£ç å¦‚ä¸‹ã€‚

```python
# å®šä¹‰æ¨¡å‹
... 

if torch.cuda.device_count() > 1:
    model = nn.DataParallel(model) # åŒ…è£…ä¸ºå¹¶è¡Œé£æ ¼æ¨¡å‹

# è®­ç»ƒæ¨¡å‹
...
features = features.to(device) # ç§»åŠ¨æ•°æ®åˆ°cuda
labels = labels.to(device) # æˆ–è€… labels = labels.cuda() if torch.cuda.is_available() else labels
...
```

## ã€‡ï¼ŒGPUç›¸å…³æ“ä½œæ±‡æ€»


```python
import torch 
from torch import nn 

# 1ï¼ŒæŸ¥çœ‹gpuä¿¡æ¯
if_cuda = torch.cuda.is_available()
print("if_cuda=",if_cuda)

gpu_count = torch.cuda.device_count()
print("gpu_count=",gpu_count)

```

    if_cuda= True
    gpu_count= 1



```python
# 2ï¼Œå°†å¼ é‡åœ¨gpuå’Œcpué—´ç§»åŠ¨
tensor = torch.rand((100,100))
tensor_gpu = tensor.to("cuda:0") # æˆ–è€… tensor_gpu = tensor.cuda()
print(tensor_gpu.device)
print(tensor_gpu.is_cuda)

tensor_cpu = tensor_gpu.to("cpu") # æˆ–è€… tensor_cpu = tensor_gpu.cpu() 
print(tensor_cpu.device)

```

    cuda:0
    True
    cpu



```python
# 3ï¼Œå°†æ¨¡å‹ä¸­çš„å…¨éƒ¨å¼ é‡ç§»åŠ¨åˆ°gpuä¸Š
net = nn.Linear(2,1)
print(next(net.parameters()).is_cuda)
net.to("cuda:0") # å°†æ¨¡å‹ä¸­çš„å…¨éƒ¨å‚æ•°å¼ é‡ä¾æ¬¡åˆ°GPUä¸Šï¼Œæ³¨æ„ï¼Œæ— éœ€é‡æ–°èµ‹å€¼ä¸º net = net.to("cuda:0")
print(next(net.parameters()).is_cuda)
print(next(net.parameters()).device)

```

    False
    True
    cuda:0



```python
# 4ï¼Œåˆ›å»ºæ”¯æŒå¤šä¸ªgpuæ•°æ®å¹¶è¡Œçš„æ¨¡å‹
linear = nn.Linear(2,1)
print(next(linear.parameters()).device)

model = nn.DataParallel(linear)
print(model.device_ids)
print(next(model.module.parameters()).device) 

#æ³¨æ„ä¿å­˜å‚æ•°æ—¶è¦æŒ‡å®šä¿å­˜model.moduleçš„å‚æ•°
torch.save(model.module.state_dict(), "model_parameter.pt") 

linear = nn.Linear(2,1)
linear.load_state_dict(torch.load("model_parameter.pt")) 

```

    cpu
    [0]
    cuda:0





    <All keys matched successfully>



## ä¸€ï¼ŒçŸ©é˜µä¹˜æ³•èŒƒä¾‹

ä¸‹é¢åˆ†åˆ«ä½¿ç”¨CPUå’ŒGPUä½œä¸€ä¸ªçŸ©é˜µä¹˜æ³•ï¼Œå¹¶æ¯”è¾ƒå…¶è®¡ç®—æ•ˆç‡ã€‚


```python
import time
import torch 
from torch import nn
```


```python
# ä½¿ç”¨cpu
a = torch.rand((10000,200))
b = torch.rand((200,10000))
tic = time.time()
c = torch.matmul(a,b)
toc = time.time()

print(toc-tic)
print(a.device)
print(b.device)
```

    0.6000046730041504
    cpu
    cpu



```python
# ä½¿ç”¨gpu
device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
a = torch.rand((10000,200),device = device) #å¯ä»¥æŒ‡å®šåœ¨GPUä¸Šåˆ›å»ºå¼ é‡
b = torch.rand((200,10000)) #ä¹Ÿå¯ä»¥åœ¨CPUä¸Šåˆ›å»ºå¼ é‡åç§»åŠ¨åˆ°GPUä¸Š
b = b.to(device) #æˆ–è€… b = b.cuda() if torch.cuda.is_available() else b 
tic = time.time()
c = torch.matmul(a,b)
toc = time.time()
print(toc-tic)
print(a.device)
print(b.device)

```

    0.8443384170532227
    cuda:0
    cuda:0



```python

```

## äºŒï¼Œçº¿æ€§å›å½’èŒƒä¾‹

ä¸‹é¢å¯¹æ¯”ä½¿ç”¨CPUå’ŒGPUè®­ç»ƒä¸€ä¸ªçº¿æ€§å›å½’æ¨¡å‹çš„æ•ˆç‡

### 1ï¼Œä½¿ç”¨CPU


```python
# å‡†å¤‡æ•°æ®
n = 1000000 #æ ·æœ¬æ•°é‡

X = 10*torch.rand([n,2])-5.0  #torch.randæ˜¯å‡åŒ€åˆ†å¸ƒ 
w0 = torch.tensor([[2.0,-3.0]])
b0 = torch.tensor([[10.0]])
Y = X@w0.t() + b0 + torch.normal( 0.0,2.0,size = [n,1])  # @è¡¨ç¤ºçŸ©é˜µä¹˜æ³•,å¢åŠ æ­£æ€æ‰°åŠ¨
```


```python
# å®šä¹‰æ¨¡å‹
class LinearRegression(nn.Module): 
    def __init__(self):
        super().__init__()
        self.w = nn.Parameter(torch.randn_like(w0))
        self.b = nn.Parameter(torch.zeros_like(b0))
    #æ­£å‘ä¼ æ’­
    def forward(self,x): 
        return x@self.w.t() + self.b
        
linear = LinearRegression() 

```


```python
# è®­ç»ƒæ¨¡å‹
optimizer = torch.optim.Adam(linear.parameters(),lr = 0.1)
loss_fn = nn.MSELoss()

def train(epoches):
    tic = time.time()
    for epoch in range(epoches):
        optimizer.zero_grad()
        Y_pred = linear(X) 
        loss = loss_fn(Y_pred,Y)
        loss.backward() 
        optimizer.step()
        if epoch%50==0:
            print({"epoch":epoch,"loss":loss.item()})
    toc = time.time()
    print("time used:",toc-tic)

train(500)
```

    {'epoch': 0, 'loss': 258.9547119140625}
    {'epoch': 50, 'loss': 33.212669372558594}
    {'epoch': 100, 'loss': 9.038525581359863}
    {'epoch': 150, 'loss': 4.485360145568848}
    {'epoch': 200, 'loss': 4.017963409423828}
    {'epoch': 250, 'loss': 3.994182825088501}
    {'epoch': 300, 'loss': 3.993659734725952}
    {'epoch': 350, 'loss': 3.9936563968658447}
    {'epoch': 400, 'loss': 3.9936563968658447}
    {'epoch': 450, 'loss': 3.9936563968658447}
    time used: 5.222184896469116


### 2ï¼Œä½¿ç”¨GPU


```python
# å‡†å¤‡æ•°æ®
n = 1000000 #æ ·æœ¬æ•°é‡

X = 10*torch.rand([n,2])-5.0  #torch.randæ˜¯å‡åŒ€åˆ†å¸ƒ 
w0 = torch.tensor([[2.0,-3.0]])
b0 = torch.tensor([[10.0]])
Y = X@w0.t() + b0 + torch.normal( 0.0,2.0,size = [n,1])  # @è¡¨ç¤ºçŸ©é˜µä¹˜æ³•,å¢åŠ æ­£æ€æ‰°åŠ¨

# æ•°æ®ç§»åŠ¨åˆ°GPUä¸Š
print("torch.cuda.is_available() = ",torch.cuda.is_available())
X = X.cuda()
Y = Y.cuda()
print("X.device:",X.device)
print("Y.device:",Y.device)
```

    torch.cuda.is_available() =  True
    X.device: cuda:0
    Y.device: cuda:0



```python
# å®šä¹‰æ¨¡å‹
class LinearRegression(nn.Module): 
    def __init__(self):
        super().__init__()
        self.w = nn.Parameter(torch.randn_like(w0))
        self.b = nn.Parameter(torch.zeros_like(b0))
    #æ­£å‘ä¼ æ’­
    def forward(self,x): 
        return x@self.w.t() + self.b
        
linear = LinearRegression() 

# ç§»åŠ¨æ¨¡å‹åˆ°GPUä¸Š
device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
linear.to(device)

#æŸ¥çœ‹æ¨¡å‹æ˜¯å¦å·²ç»ç§»åŠ¨åˆ°GPUä¸Š
print("if on cuda:",next(linear.parameters()).is_cuda)

```

    if on cuda: True



```python
# è®­ç»ƒæ¨¡å‹
optimizer = torch.optim.Adam(linear.parameters(),lr = 0.1)
loss_fn = nn.MSELoss()

def train(epoches):
    tic = time.time()
    for epoch in range(epoches):
        optimizer.zero_grad()
        Y_pred = linear(X) 
        loss = loss_fn(Y_pred,Y)
        loss.backward() 
        optimizer.step()
        if epoch%50==0:
            print({"epoch":epoch,"loss":loss.item()})
    toc = time.time()
    print("time used:",toc-tic)
    
train(500)
```

    {'epoch': 0, 'loss': 153.66574096679688}
    {'epoch': 50, 'loss': 32.86173629760742}
    {'epoch': 100, 'loss': 9.03520679473877}
    {'epoch': 150, 'loss': 4.485783576965332}
    {'epoch': 200, 'loss': 4.018568515777588}
    {'epoch': 250, 'loss': 3.994813919067383}
    {'epoch': 300, 'loss': 3.9942924976348877}
    {'epoch': 350, 'loss': 3.994288921356201}
    {'epoch': 400, 'loss': 3.9942891597747803}
    {'epoch': 450, 'loss': 3.9942891597747803}
    time used: 0.5444216728210449



```python

```

## ä¸‰ï¼Œå›¾ç‰‡åˆ†ç±»èŒƒä¾‹


```python
import torch 
from torch import nn 

import torchvision 
from torchvision import transforms
```


```python
transform = transforms.Compose([transforms.ToTensor()])

ds_train = torchvision.datasets.MNIST(root="mnist/",train=True,download=True,transform=transform)
ds_val = torchvision.datasets.MNIST(root="mnist/",train=False,download=True,transform=transform)

dl_train =  torch.utils.data.DataLoader(ds_train, batch_size=128, shuffle=True, num_workers=2)
dl_val =  torch.utils.data.DataLoader(ds_val, batch_size=128, shuffle=False, num_workers=2)

print(len(ds_train))
print(len(ds_val))

```

    Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz
    Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to mnist/MNIST/raw/train-images-idx3-ubyte.gz



      0%|          | 0/9912422 [00:00<?, ?it/s]


    Extracting mnist/MNIST/raw/train-images-idx3-ubyte.gz to mnist/MNIST/raw
    
    Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz
    Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to mnist/MNIST/raw/train-labels-idx1-ubyte.gz



      0%|          | 0/28881 [00:00<?, ?it/s]


    Extracting mnist/MNIST/raw/train-labels-idx1-ubyte.gz to mnist/MNIST/raw
    
    Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz
    Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to mnist/MNIST/raw/t10k-images-idx3-ubyte.gz



      0%|          | 0/1648877 [00:00<?, ?it/s]


    Extracting mnist/MNIST/raw/t10k-images-idx3-ubyte.gz to mnist/MNIST/raw
    
    Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz
    Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to mnist/MNIST/raw/t10k-labels-idx1-ubyte.gz



      0%|          | 0/4542 [00:00<?, ?it/s]


    Extracting mnist/MNIST/raw/t10k-labels-idx1-ubyte.gz to mnist/MNIST/raw
    
    60000
    10000



```python
def create_net():
    net = nn.Sequential()
    net.add_module("conv1",nn.Conv2d(in_channels=1,out_channels=32,kernel_size = 3))
    net.add_module("pool1",nn.MaxPool2d(kernel_size = 2,stride = 2))
    net.add_module("conv2",nn.Conv2d(in_channels=32,out_channels=64,kernel_size = 5))
    net.add_module("pool2",nn.MaxPool2d(kernel_size = 2,stride = 2))
    net.add_module("dropout",nn.Dropout2d(p = 0.1))
    net.add_module("adaptive_pool",nn.AdaptiveMaxPool2d((1,1)))
    net.add_module("flatten",nn.Flatten())
    net.add_module("linear1",nn.Linear(64,32))
    net.add_module("relu",nn.ReLU())
    net.add_module("linear2",nn.Linear(32,10))
    return net

net = create_net()
print(net)
```

    Sequential(
      (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))
      (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (conv2): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1))
      (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (dropout): Dropout2d(p=0.1, inplace=False)
      (adaptive_pool): AdaptiveMaxPool2d(output_size=(1, 1))
      (flatten): Flatten(start_dim=1, end_dim=-1)
      (linear1): Linear(in_features=64, out_features=32, bias=True)
      (relu): ReLU()
      (linear2): Linear(in_features=32, out_features=10, bias=True)
    )


### 1ï¼Œä½¿ç”¨CPUè¿›è¡Œè®­ç»ƒ


```python
import os,sys,time
import numpy as np
import pandas as pd
import datetime 
from tqdm import tqdm 

import torch
from torch import nn 
from copy import deepcopy
from torchmetrics import Accuracy
#æ³¨ï¼šå¤šåˆ†ç±»ä½¿ç”¨torchmetricsä¸­çš„è¯„ä¼°æŒ‡æ ‡ï¼ŒäºŒåˆ†ç±»ä½¿ç”¨torchkeras.metricsä¸­çš„è¯„ä¼°æŒ‡æ ‡

def printlog(info):
    nowtime = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    print("\n"+"=========="*8 + "%s"%nowtime)
    print(str(info)+"\n")
    

net = create_net() 

loss_fn = nn.CrossEntropyLoss()
optimizer= torch.optim.Adam(net.parameters(),lr = 0.01)   
metrics_dict = {"acc":Accuracy(task='multiclass',num_classes=10)}

epochs = 3 
ckpt_path='checkpoint.pt'

#early_stoppingç›¸å…³è®¾ç½®
monitor="val_acc"
patience=1
mode="max"

history = {}

for epoch in range(1, epochs+1):
    printlog("Epoch {0} / {1}".format(epoch, epochs))

    # 1ï¼Œtrain -------------------------------------------------  
    net.train()
    
    total_loss,step = 0,0
    
    loop = tqdm(enumerate(dl_train), total =len(dl_train),file=sys.stdout)
    train_metrics_dict = deepcopy(metrics_dict) 
    
    for i, batch in loop: 
        
        features,labels = batch
        #forward
        preds = net(features)
        loss = loss_fn(preds,labels)
        
        #backward
        loss.backward()
        optimizer.step()
        optimizer.zero_grad()
            
        #metrics
        step_metrics = {"train_"+name:metric_fn(preds, labels).item() 
                        for name,metric_fn in train_metrics_dict.items()}
        
        step_log = dict({"train_loss":loss.item()},**step_metrics)

        total_loss += loss.item()
        
        step+=1
        if i!=len(dl_train)-1:
            loop.set_postfix(**step_log)
        else:
            epoch_loss = total_loss/step
            epoch_metrics = {"train_"+name:metric_fn.compute().item() 
                             for name,metric_fn in train_metrics_dict.items()}
            epoch_log = dict({"train_loss":epoch_loss},**epoch_metrics)
            loop.set_postfix(**epoch_log)

            for name,metric_fn in train_metrics_dict.items():
                metric_fn.reset()
                
    for name, metric in epoch_log.items():
        history[name] = history.get(name, []) + [metric]
        

    # 2ï¼Œvalidate -------------------------------------------------
    net.eval()
    
    total_loss,step = 0,0
    loop = tqdm(enumerate(dl_val), total =len(dl_val),file=sys.stdout)
    
    val_metrics_dict = deepcopy(metrics_dict) 
    
    with torch.no_grad():
        for i, batch in loop: 

            features,labels = batch
            
            #forward
            preds = net(features)
            loss = loss_fn(preds,labels)

            #metrics
            step_metrics = {"val_"+name:metric_fn(preds, labels).item() 
                            for name,metric_fn in val_metrics_dict.items()}

            step_log = dict({"val_loss":loss.item()},**step_metrics)

            total_loss += loss.item()
            step+=1
            if i!=len(dl_val)-1:
                loop.set_postfix(**step_log)
            else:
                epoch_loss = (total_loss/step)
                epoch_metrics = {"val_"+name:metric_fn.compute().item() 
                                 for name,metric_fn in val_metrics_dict.items()}
                epoch_log = dict({"val_loss":epoch_loss},**epoch_metrics)
                loop.set_postfix(**epoch_log)

                for name,metric_fn in val_metrics_dict.items():
                    metric_fn.reset()
                    
    epoch_log["epoch"] = epoch           
    for name, metric in epoch_log.items():
        history[name] = history.get(name, []) + [metric]

    # 3ï¼Œearly-stopping -------------------------------------------------
    arr_scores = history[monitor]
    best_score_idx = np.argmax(arr_scores) if mode=="max" else np.argmin(arr_scores)
    if best_score_idx==len(arr_scores)-1:
        torch.save(net.state_dict(),ckpt_path)
        print("<<<<<< reach best {0} : {1} >>>>>>".format(monitor,
             arr_scores[best_score_idx]))
    if len(arr_scores)-best_score_idx>patience:
        print("<<<<<< {} without improvement in {} epoch, early stopping >>>>>>".format(
            monitor,patience))
        break 
    net.load_state_dict(torch.load(ckpt_path))
    
dfhistory = pd.DataFrame(history)
```

    
    ================================================================================2023-08-02 09:22:53
    Epoch 1 / 3
    
    100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 469/469 [00:35<00:00, 13.11it/s, train_acc=0.9, train_loss=0.312]   
    100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 79/79 [00:03<00:00, 22.00it/s, val_acc=0.965, val_loss=0.111] 
    <<<<<< reach best val_acc : 0.9646000266075134 >>>>>>
    
    ================================================================================2023-08-02 09:23:33
    Epoch 2 / 3
    
    100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 469/469 [00:35<00:00, 13.29it/s, train_acc=0.966, train_loss=0.109] 
    100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 79/79 [00:03<00:00, 22.50it/s, val_acc=0.975, val_loss=0.0814]
    <<<<<< reach best val_acc : 0.9749000072479248 >>>>>>
    
    ================================================================================2023-08-02 09:24:12
    Epoch 3 / 3
    
    100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 469/469 [00:34<00:00, 13.50it/s, train_acc=0.971, train_loss=0.095] 
    100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 79/79 [00:03<00:00, 23.03it/s, val_acc=0.964, val_loss=0.12]   
    <<<<<< val_acc without improvement in 1 epoch, early stopping >>>>>>


CPUæ¯ä¸ªEpochå¤§æ¦‚40s

### 2ï¼Œä½¿ç”¨GPUè¿›è¡Œè®­ç»ƒ


```python
import os,sys,time
import numpy as np
import pandas as pd
import datetime 
from tqdm import tqdm 

import torch
from torch import nn 
from copy import deepcopy
from torchmetrics import Accuracy
#æ³¨ï¼šå¤šåˆ†ç±»ä½¿ç”¨torchmetricsä¸­çš„è¯„ä¼°æŒ‡æ ‡ï¼ŒäºŒåˆ†ç±»ä½¿ç”¨torchkeras.metricsä¸­çš„è¯„ä¼°æŒ‡æ ‡

def printlog(info):
    nowtime = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    print("\n"+"=========="*8 + "%s"%nowtime)
    print(str(info)+"\n")
    
net = create_net() 


loss_fn = nn.CrossEntropyLoss()
optimizer= torch.optim.Adam(net.parameters(),lr = 0.01)   
metrics_dict = {"acc":Accuracy(task='multiclass',num_classes=10)}


# =========================ç§»åŠ¨æ¨¡å‹åˆ°GPUä¸Š==============================
device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
net.to(device)
loss_fn.to(device)
for name,fn in metrics_dict.items():
    fn.to(device)
# ====================================================================


epochs = 5 
ckpt_path='checkpoint.pt'

#early_stoppingç›¸å…³è®¾ç½®
monitor="val_acc"
patience=1
mode="max"

history = {}

for epoch in range(1, epochs+1):
    printlog("Epoch {0} / {1}".format(epoch, epochs))

    # 1ï¼Œtrain -------------------------------------------------  
    net.train()
    
    total_loss,step = 0,0
    
    loop = tqdm(enumerate(dl_train), total =len(dl_train),file=sys.stdout)
    train_metrics_dict = deepcopy(metrics_dict) 
    
    for i, batch in loop: 
        
        features,labels = batch
        
        # =========================ç§»åŠ¨æ•°æ®åˆ°GPUä¸Š==============================
        features = features.to(device)
        labels = labels.to(device)
        # ====================================================================
        
        #forward
        preds = net(features)
        loss = loss_fn(preds,labels)
        
        #backward
        loss.backward()
        optimizer.step()
        optimizer.zero_grad()
            
        #metrics
        step_metrics = {"train_"+name:metric_fn(preds, labels).item() 
                        for name,metric_fn in train_metrics_dict.items()}
        
        step_log = dict({"train_loss":loss.item()},**step_metrics)

        total_loss += loss.item()
        
        step+=1
        if i!=len(dl_train)-1:
            loop.set_postfix(**step_log)
        else:
            epoch_loss = total_loss/step
            epoch_metrics = {"train_"+name:metric_fn.compute().item() 
                             for name,metric_fn in train_metrics_dict.items()}
            epoch_log = dict({"train_loss":epoch_loss},**epoch_metrics)
            loop.set_postfix(**epoch_log)

            for name,metric_fn in train_metrics_dict.items():
                metric_fn.reset()
                
    for name, metric in epoch_log.items():
        history[name] = history.get(name, []) + [metric]
        

    # 2ï¼Œvalidate -------------------------------------------------
    net.eval()
    
    total_loss,step = 0,0
    loop = tqdm(enumerate(dl_val), total =len(dl_val),file=sys.stdout)
    
    val_metrics_dict = deepcopy(metrics_dict) 
    
    with torch.no_grad():
        for i, batch in loop: 

            features,labels = batch
            
            # =========================ç§»åŠ¨æ•°æ®åˆ°GPUä¸Š==============================
            features = features.to(device)
            labels = labels.to(device)
            # ====================================================================
            
            #forward
            preds = net(features)
            loss = loss_fn(preds,labels)

            #metrics
            step_metrics = {"val_"+name:metric_fn(preds, labels).item() 
                            for name,metric_fn in val_metrics_dict.items()}

            step_log = dict({"val_loss":loss.item()},**step_metrics)

            total_loss += loss.item()
            step+=1
            if i!=len(dl_val)-1:
                loop.set_postfix(**step_log)
            else:
                epoch_loss = (total_loss/step)
                epoch_metrics = {"val_"+name:metric_fn.compute().item() 
                                 for name,metric_fn in val_metrics_dict.items()}
                epoch_log = dict({"val_loss":epoch_loss},**epoch_metrics)
                loop.set_postfix(**epoch_log)

                for name,metric_fn in val_metrics_dict.items():
                    metric_fn.reset()
                    
    epoch_log["epoch"] = epoch           
    for name, metric in epoch_log.items():
        history[name] = history.get(name, []) + [metric]

    # 3ï¼Œearly-stopping -------------------------------------------------
    arr_scores = history[monitor]
    best_score_idx = np.argmax(arr_scores) if mode=="max" else np.argmin(arr_scores)
    if best_score_idx==len(arr_scores)-1:
        torch.save(net.state_dict(),ckpt_path)
        print("<<<<<< reach best {0} : {1} >>>>>>".format(monitor,
             arr_scores[best_score_idx]))
    if len(arr_scores)-best_score_idx>patience:
        print("<<<<<< {} without improvement in {} epoch, early stopping >>>>>>".format(
            monitor,patience))
        break 
    net.load_state_dict(torch.load(ckpt_path))
    
dfhistory = pd.DataFrame(history)
```

    
    ================================================================================2023-08-02 09:27:40
    Epoch 1 / 5
    
    100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 469/469 [00:14<00:00, 33.06it/s, train_acc=0.91, train_loss=0.283]  
    100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 79/79 [00:01<00:00, 56.00it/s, val_acc=0.972, val_loss=0.0912]
    <<<<<< reach best val_acc : 0.972000002861023 >>>>>>
    
    ================================================================================2023-08-02 09:27:56
    Epoch 2 / 5
    
    100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 469/469 [00:09<00:00, 50.56it/s, train_acc=0.968, train_loss=0.105] 
    100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 79/79 [00:01<00:00, 40.13it/s, val_acc=0.98, val_loss=0.0672] 
    <<<<<< reach best val_acc : 0.9800000190734863 >>>>>>
    
    ================================================================================2023-08-02 09:28:08
    Epoch 3 / 5
    
    100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 469/469 [00:09<00:00, 51.60it/s, train_acc=0.972, train_loss=0.0926]
    100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 79/79 [00:01<00:00, 55.83it/s, val_acc=0.964, val_loss=0.121] 
    <<<<<< val_acc without improvement in 1 epoch, early stopping >>>>>>


ä½¿ç”¨GPUåæ¯ä¸ªEpochåªéœ€è¦10ç§’é’Ÿå·¦å³ï¼Œæå‡äº†4å€ã€‚


## å››ï¼Œtorchkeras.KerasModelä¸­ä½¿ç”¨GPU

ä»ä¸Šé¢çš„ä¾‹å­å¯ä»¥çœ‹åˆ°ï¼Œåœ¨pytorchä¸­ä½¿ç”¨GPUå¹¶ä¸å¤æ‚ï¼Œä½†å¯¹äºç»å¸¸ç‚¼ä¸¹çš„åŒå­¦æ¥è¯´ï¼Œæ¨¡å‹å’Œæ•°æ®è€æ˜¯ç§»æ¥ç§»å»è¿˜æ˜¯è›®éº»çƒ¦çš„ã€‚

ä¸€ä¸å°å¿ƒå°±ä¼šå¿˜äº†ç§»åŠ¨æŸäº›æ•°æ®æˆ–è€…æŸäº›moduleï¼Œå¯¼è‡´æŠ¥é”™ã€‚

torchkeras.KerasModel åœ¨è®¾è®¡çš„æ—¶å€™è€ƒè™‘åˆ°äº†è¿™ä¸€ç‚¹ï¼Œå¦‚æœç¯å¢ƒå½“ä¸­å­˜åœ¨å¯ç”¨çš„GPUï¼Œä¼šè‡ªåŠ¨ä½¿ç”¨GPUï¼Œåä¹‹åˆ™ä½¿ç”¨CPUã€‚

é€šè¿‡å¼•å…¥accelerateçš„ä¸€äº›åŸºç¡€åŠŸèƒ½ï¼Œtorchkeras.KerasModelä»¥éå¸¸ä¼˜é›…çš„æ–¹å¼åœ¨GPUå’ŒCPUä¹‹é—´åˆ‡æ¢ã€‚

è¯¦ç»†å®ç°å¯ä»¥å‚è€ƒtorchkeras.KerasModelçš„æºç ã€‚


```python
import  accelerate 
accelerator = accelerate.Accelerator()
print(accelerator.device)  
```

    cuda



```python
from torchkeras import KerasModel 
from torchmetrics import Accuracy

net = create_net() 
model = KerasModel(net,
                   loss_fn=nn.CrossEntropyLoss(),
                   metrics_dict = {"acc":Accuracy(task='multiclass',num_classes=10)},
                   optimizer = torch.optim.Adam(net.parameters(),lr = 0.01)  )

model.fit(
    train_data = dl_train,
    val_data= dl_val,
    epochs=10,
    patience=3,
    monitor="val_acc", 
    mode="max")
```

    [0;31m<<<<<< âš¡ï¸ cuda is used >>>>>>[0m



    
![png](output_41_1.png)
    




<style>
    /* background: */
    progress::-webkit-progress-bar {background-color: #CDCDCD; width: 100%;}
    progress {background-color: #CDCDCD;}

    /* value: */
    progress::-webkit-progress-value {background-color: #00BFFF  !important;}
    progress::-moz-progress-bar {background-color: #00BFFF  !important;}
    progress {color: #00BFFF ;}

    /* optional */
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #000000;
    }
</style>





<div>
  <progress value='8' class='progress-bar-interrupted' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>
  80.00% [8/10] [01:35<00:23]
  <br>
  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ100.00% [79/79] [val_loss=0.0731, val_acc=0.9795]
</div>



    [0;31m<<<<<< val_acc without improvement in 3 epoch,early stopping >>>>>> 
    [0m





<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>epoch</th>
      <th>train_loss</th>
      <th>train_acc</th>
      <th>lr</th>
      <th>val_loss</th>
      <th>val_acc</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>0.327403</td>
      <td>0.893783</td>
      <td>0.01</td>
      <td>0.105610</td>
      <td>0.9660</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2</td>
      <td>0.109891</td>
      <td>0.966483</td>
      <td>0.01</td>
      <td>0.086295</td>
      <td>0.9746</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3</td>
      <td>0.092442</td>
      <td>0.972733</td>
      <td>0.01</td>
      <td>0.058266</td>
      <td>0.9825</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4</td>
      <td>0.085473</td>
      <td>0.975367</td>
      <td>0.01</td>
      <td>0.072749</td>
      <td>0.9806</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5</td>
      <td>0.079213</td>
      <td>0.977350</td>
      <td>0.01</td>
      <td>0.059756</td>
      <td>0.9832</td>
    </tr>
    <tr>
      <th>5</th>
      <td>6</td>
      <td>0.077976</td>
      <td>0.977800</td>
      <td>0.01</td>
      <td>0.081202</td>
      <td>0.9768</td>
    </tr>
    <tr>
      <th>6</th>
      <td>7</td>
      <td>0.074797</td>
      <td>0.978950</td>
      <td>0.01</td>
      <td>0.076534</td>
      <td>0.9821</td>
    </tr>
    <tr>
      <th>7</th>
      <td>8</td>
      <td>0.072074</td>
      <td>0.980133</td>
      <td>0.01</td>
      <td>0.073126</td>
      <td>0.9795</td>
    </tr>
  </tbody>
</table>
</div>



### 

**å¦‚æœæœ¬ä¹¦å¯¹ä½ æœ‰æ‰€å¸®åŠ©ï¼Œæƒ³é¼“åŠ±ä¸€ä¸‹ä½œè€…ï¼Œè®°å¾—ç»™æœ¬é¡¹ç›®åŠ ä¸€é¢—æ˜Ÿæ˜Ÿstarâ­ï¸ï¼Œå¹¶åˆ†äº«ç»™ä½ çš„æœ‹å‹ä»¬å–”ğŸ˜Š!** 

å¦‚æœå¯¹æœ¬ä¹¦å†…å®¹ç†è§£ä¸Šæœ‰éœ€è¦è¿›ä¸€æ­¥å’Œä½œè€…äº¤æµçš„åœ°æ–¹ï¼Œæ¬¢è¿åœ¨å…¬ä¼—å·"ç®—æ³•ç¾é£Ÿå±‹"ä¸‹ç•™è¨€ã€‚ä½œè€…æ—¶é—´å’Œç²¾åŠ›æœ‰é™ï¼Œä¼šé…Œæƒ…äºˆä»¥å›å¤ã€‚

ä¹Ÿå¯ä»¥åœ¨å…¬ä¼—å·åå°å›å¤å…³é”®å­—ï¼š**åŠ ç¾¤**ï¼ŒåŠ å…¥è¯»è€…äº¤æµç¾¤å’Œå¤§å®¶è®¨è®ºã€‚

![ç®—æ³•ç¾é£Ÿå±‹logo.png](https://tva1.sinaimg.cn/large/e6c9d24egy1h41m2zugguj20k00b9q46.jpg)
